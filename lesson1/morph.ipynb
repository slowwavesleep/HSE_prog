{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "import pymorphy2\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterMorphology:\n",
    "    \"\"\"\n",
    "    A class for fast morphological analysis and word vectorization of texts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.morpho = pymorphy2.MorphAnalyzer()\n",
    "        self.cache = {}  # word form: initial word form\n",
    "        self.dictionary = {}  # initial word form: vector position\n",
    "        self.stop_words = set()\n",
    "\n",
    "    def analyze_text(self, text):\n",
    "        \"\"\"\n",
    "        This method performs morphological analysis of input text.\n",
    "        It isolates words written only in cyrillic letters.\n",
    "\n",
    "\n",
    "        Args:\n",
    "            text: A string of text to analyze.\n",
    "\n",
    "        Returns:\n",
    "           A list of words in their initial form excluding stop words.\n",
    "\n",
    "        \"\"\"\n",
    "        words = [word[0].lower() for word in re.findall(r\"([А-ЯЁа-яё]+(-[А-ЯЁа-яё]+)*)\", text) if\n",
    "                 self.check_stop_words(word[0].lower())]\n",
    "        return self.analyze_words(words)\n",
    "\n",
    "    def analyze_words(self, words):\n",
    "        \"\"\"\n",
    "        This method is used for morphological analysis.\n",
    "\n",
    "        Args:\n",
    "            words: A list of words to analyse.\n",
    "\n",
    "        Returns:\n",
    "           A list of normalized words.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for word in words:\n",
    "            if word in self.cache:\n",
    "                res.append(self.cache[word])\n",
    "            else:\n",
    "                norm = self.morpho.parse(word)[0].normal_form\n",
    "                res.append(norm)\n",
    "                self.cache[word] = norm\n",
    "                if norm not in self.dictionary:\n",
    "                    self.dictionary[norm] = len(self.dictionary) + 1\n",
    "        return res\n",
    "\n",
    "    def clear_dict(self):\n",
    "        \"\"\"\n",
    "        Clears the class dictionary.\n",
    "        \"\"\"\n",
    "        self.dictionary.clear()\n",
    "\n",
    "    def check_stop_words(self, word):\n",
    "        \"\"\"\n",
    "        Checks whether a word is a stop word or not.\n",
    "\n",
    "        Args:\n",
    "            word: A word to check.\n",
    "\n",
    "        Returns:\n",
    "           A boolean value. True if given word was not found in the set of stop words, False otherwise.\n",
    "        \"\"\"\n",
    "        return False if word.lower() in self.stop_words else True\n",
    "        \n",
    "    def clear_stop_words(self):\n",
    "        \"\"\"\n",
    "        A method to clear an existing set of stop words.\n",
    "        \"\"\"\n",
    "        self.stop_words.clear()\n",
    "\n",
    "    @staticmethod\n",
    "    def cosine_similarity(a, b):\n",
    "        \"\"\"\n",
    "        This method evaluates cosine distance between two word vectors.\n",
    "        \n",
    "        Args:\n",
    "            a: The first vector.\n",
    "            b: The second vector.\n",
    "            \n",
    "        Return:\n",
    "            A floating point value between 0 and 1 where 0 is least similar and 1 is most similar. \n",
    "\n",
    "        \"\"\"\n",
    "        #if not a or not b:\n",
    "        if not len(a) or not len(b): #the trick above doesn't work numpy arrays\n",
    "            raise ValueError(\"Vectors can't be empty.\")\n",
    "\n",
    "        if isinstance(a, (list, np.ndarray)) and isinstance(b, (list, np.ndarray)):\n",
    "            if len(a) != len(b):\n",
    "                warn(\"The lengths of input vectors are not matching. \" +\n",
    "                \"The result is evaluated using the shortest vector's length. \")\n",
    "                return np.sum([x * y for x, y in zip(a, b)]) / np.sqrt(np.dot(a, a) * np.dot(b, b))\n",
    "            else:\n",
    "                return np.dot(a, b) / np.sqrt(np.dot(a, a) * np.dot(b, b))\n",
    "\n",
    "        elif isinstance(a, dict) and isinstance(b, dict):\n",
    "            numerator = np.sum([a[k] * b[k] for k in set(a.keys()).intersection(b.keys())])\n",
    "            denominator = np.sqrt(sum(map(lambda x: x ** 2, a.values())) * sum(map(lambda x: x ** 2, b.values())))\n",
    "            return numerator / denominator\n",
    "\n",
    "        else:\n",
    "            raise TypeError(\"Vector type or vector type combination is not supported.\")\n",
    "        \n",
    "    def fill_stop_words(self, stop_words):\n",
    "        \"\"\"\n",
    "        This method is used to fill or update the set of stop words.\n",
    "        It is assumed that the input list contains words in lowercase.\n",
    "\n",
    "        Args:\n",
    "            stop_words: An iterable containing words considered unimportant.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        self.stop_words.update(stop_words)\n",
    "\n",
    "    def filter_stop_words(self, words):\n",
    "        \"\"\"\n",
    "        A method that removes stop words from a given list of words.\n",
    "\n",
    "        Args:\n",
    "            words: A list of words to filter.\n",
    "\n",
    "        Returns:\n",
    "            A list of words with stop words removed.\n",
    "        \"\"\"\n",
    "        return list(filter(self.check_stop_words, words))\n",
    "    \n",
    "    def form_dict(self, texts):\n",
    "        \"\"\"\n",
    "        Fill the class dictionary without generating word vectors.\n",
    "\n",
    "        Args:\n",
    "            texts: An iterable containing texts.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        for text in texts:\n",
    "            for word in text:\n",
    "                if word not in self.cache:\n",
    "                    norm = self.morpho.parse(word)[0].normal_form\n",
    "                    self.cache[word] = norm\n",
    "                    if norm not in self.dictionary:\n",
    "                        self.dictionary[norm] = len(self.dictionary)\n",
    "\n",
    "    @staticmethod\n",
    "    def jaccard_coefficient(a, b):\n",
    "        \"\"\"\n",
    "        This method evaluates Jaccard Coefficient (AKA Intersection over Union) of two vectors.\n",
    "        \n",
    "        Args:\n",
    "            a: The first vector.\n",
    "            b: The second vector.\n",
    "            \n",
    "        Returns:\n",
    "            A floating point value between 0 and 1.\n",
    "        \"\"\"\n",
    "        #if not a or not b:\n",
    "        if not len(a) or not len(b):\n",
    "            raise ValueError(\"Vectors can't be empty.\")\n",
    "\n",
    "        if isinstance(a, (list, np.ndarray)) and isinstance(b, (list, np.ndarray)):\n",
    "            if len(a) != len(b):\n",
    "                warn(\"The lengths of input vectors are not matching. \" +\n",
    "                     \"The result is evaluated using the shortest vector's length. \")\n",
    "            return len([x * y for x, y in zip(a, b) if x * y]) / len([x + y for x, y in zip(a, b) if x + y])\n",
    "        elif isinstance(a, dict) and isinstance(b, dict):\n",
    "            return len(set(a).intersection(b)) / len(set(a).union(b))\n",
    "        else:\n",
    "            raise TypeError(\"Vector type not supported.\")\n",
    "        \n",
    "    def vectorize_as_array(self, words):\n",
    "        \"\"\"\n",
    "        This method transforms an iterable of tokens into dense vector form.\n",
    "        The position of each of word in the vector is stored in the class dictionary\n",
    "        with the word itself as a key.\n",
    "        \n",
    "        Args:\n",
    "            words: An iterables of tokens.\n",
    "            \n",
    "        Returns:\n",
    "            A numpy array where each element is absolute frequency of a word and\n",
    "            the position corresponds to the value of a given word in the dictionary.\n",
    "            Contains all the words from the class dictionary even if the frequency\n",
    "            is zero.\n",
    "        \"\"\"\n",
    "        for word in words:\n",
    "            if word not in self.cache:\n",
    "                norm = self.morpho.parse(word)[0].normal_form\n",
    "                self.cache[word] = norm\n",
    "                if norm not in self.dictionary:\n",
    "                    self.dictionary[norm] = len(self.dictionary.keys())\n",
    "        word_vector = np.zeros((len(self.dictionary)))\n",
    "        for word in words:\n",
    "            word_vector[self.dictionary[self.cache[word]]] += 1\n",
    "        return word_vector\n",
    "\n",
    "    def vectorize_as_dict(self, words):\n",
    "        \"\"\"\n",
    "        This method transforms an iterable of tokens into sparse vector form.\n",
    "\n",
    "        Args:\n",
    "            words: An iterable consisting of tokens.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing initial forms of words as keys and their\n",
    "            corresponding absolute frequencies as values.\n",
    "        \"\"\"\n",
    "        word_vector = {}\n",
    "        for word in words:\n",
    "            if word in self.cache:\n",
    "                word_vector[self.cache[word]] = word_vector.get(self.cache[word], 0) + 1  # absolute word frequency\n",
    "            else:\n",
    "                norm = self.morpho.parse(word)[0].normal_form\n",
    "                self.cache[word] = norm\n",
    "                word_vector[norm] = word_vector.get(norm, 0) + 1  # default value 0 if no value found by key\n",
    "                if norm not in self.dictionary:\n",
    "                    self.dictionary[norm] = len(self.dictionary)\n",
    "        return word_vector\n",
    "\n",
    "    def vectorize_as_list(self, words):\n",
    "        \"\"\"\n",
    "        Transforms an iterable of tokens into a dense vector represenation.\n",
    "        The position of each word is stored in the class dictionary.\n",
    "\n",
    "        Args:\n",
    "            words: A list of tokens to transform.\n",
    "\n",
    "        Returns:\n",
    "            A list where each element is absolute frequency of a word and\n",
    "            the position corresponds to the value of a given word in the dictionary.\n",
    "            Contains all the words from the class dictionary even if the frequency\n",
    "            is zero.\n",
    "        \"\"\"\n",
    "        for word in words:\n",
    "            if word not in self.cache:\n",
    "                norm = self.morpho.parse(word)[0].normal_form\n",
    "                self.cache[word] = norm\n",
    "                if norm not in self.dictionary:\n",
    "                    self.dictionary[norm] = len(self.dictionary.keys())\n",
    "        word_vector = [0 for _ in self.dictionary]\n",
    "        for word in words:\n",
    "            word_vector[self.dictionary[self.cache[word]]] += 1\n",
    "        return word_vector\n",
    "\n",
    "    def vectorize_as_list2(self, words):\n",
    "        \"\"\"\n",
    "        Transforms an iterable of tokens into a dense vector represenation.\n",
    "        The position of each word is stored in the class dictionary.\n",
    "        Only words found in the class dictionary are accounted for, i.e.\n",
    "        no new words are added to the class dictionary.\n",
    "\n",
    "        Args:\n",
    "            words: A list of tokens to transform.\n",
    "\n",
    "        Returns:\n",
    "            A list where each element is absolute frequency of a word and\n",
    "            the position corresponds to the value of a given word in the dictionary.\n",
    "            Contains all the words from the class dictionary even if the frequency\n",
    "            is zero.\n",
    "        \"\"\"\n",
    "        word_vector = [0 for _ in self.dictionary]\n",
    "        for word in words:\n",
    "            if word in self.cache:\n",
    "                word_vector[self.dictionary[self.cache[word]]] += 1\n",
    "        return word_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = BetterMorphology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('russian')\n",
    "m.fill_stop_words(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['коэффициент',\n",
       " 'жаккара',\n",
       " 'отношение',\n",
       " 'количество',\n",
       " 'слово',\n",
       " 'встречаться',\n",
       " 'оба',\n",
       " 'текст',\n",
       " 'объединение',\n",
       " 'лексика']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.analyze_text('Коэффициент Жаккара - отношение количества слов, встречающихся в обоих текстах к объединению лексики.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/war_and_peace.txt\", encoding='utf-8') as f:\n",
    "    war_and_peace = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sebastopol.txt', encoding='utf-8') as f:\n",
    "    seba = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "words1 = m.analyze_text(war_and_peace)\n",
    "words2 = m.analyze_text(seba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "words1 = m.vectorize_as_dict(words1)\n",
    "words2 = m.vectorize_as_dict(words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7192171320999665"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.cosine_similarity(words1, words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/master.txt', encoding='cp1251') as f: # Мастер и Маргарита\n",
    "    mast = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "words3 = m.analyze_text(mast)\n",
    "words3 = m.vectorize_as_dict(words3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5716111265611228"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.cosine_similarity(words1, words3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1861354825545807"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.jaccard_coefficient(words1, words3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/veyr/index_split_017.xhtml\", encoding='utf-8') as f: # Грузим главу 15, она побольше.\n",
    "    veyr = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words4 = m.analyze_text(veyr)\n",
    "words4 = m.vectorize_as_dict(words4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5010908763905298"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.cosine_similarity(words1, words4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4283925404605853"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.cosine_similarity(words3, words4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_arr = m.vectorize_as_array(m.analyze_text(war_and_peace))\n",
    "seb_arr = m.vectorize_as_array(m.analyze_text(seba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7192064466651534"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.cosine_similarity(war_arr, seb_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15594405594405594"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.jaccard_coefficient(war_arr, seb_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
